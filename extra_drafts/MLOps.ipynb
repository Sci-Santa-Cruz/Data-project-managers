{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ciclo de vida de desarrollo de modelos (MDLC) es un término que se usa comúnmente para describir el flujo entre el entrenamiento y la inferencia. La Figura 1-1 es una representación visual de esta interacción continua, donde al activar una actualización del modelo, el ciclo completo comienza una vez más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/MLOps/kfml_0101.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Dónde encaja Kubeflow?\n",
    "\n",
    "Kubeflow es una colección de herramientas nativas de la nube para todas las etapas de MDLC (exploración de datos, preparación de características, entrenamiento / ajuste de modelos, servicio de modelos, pruebas de modelos y control de versiones de modelos). Kubeflow también tiene herramientas que permiten que estas herramientas tradicionalmente separadas funcionen juntas sin problemas. Una parte importante de esta herramienta es el sistema de tuberías, que permite a los usuarios construir tuberías integradas de extremo a extremo que conectan todos los componentes de su MDLC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubeflow es para científicos de datos e ingenieros de datos que buscan construir implementaciones de aprendizaje automático de grado de producción. Kubeflow se puede ejecutar localmente en su entorno de desarrollo o en un clúster de producción. A menudo, las tuberías se desarrollarán localmente y se migrarán una vez que estén listas. Kubeflow proporciona un sistema unificado, aprovechando Kubernetes para contenerización y escalabilidad, para la portabilidad y repetibilidad de sus canalizaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué Containerize?\n",
    "\n",
    "El aislamiento proporcionado por los contenedores permite que las etapas de aprendizaje automático sean portátiles y reproducibles. Las aplicaciones en contenedores están aisladas del resto de su máquina y tienen todos sus requisitos incluidos (desde el sistema operativo hacia arriba).1La contenedorización significa que no habrá más conversaciones que incluyan \"Funcionó en mi máquina\" o \"Oh, sí, nos olvidamos de solo una, necesitas este paquete adicional\".Los contenedores se construyen en capas componibles, lo que le permite utilizar otro contenedor como base.Por ejemplo, si tiene un nuevo biblioteca de procesamiento de lenguaje natural (NLP) que desea usar, puede agregarla sobre el contenedor existente; no tiene que comenzar desde cero cada vez. La composibilidad le permite reutilizar una base común; por ejemplo, los contenedores R y Python que usamos comparten un contenedor Debian base.Una preocupación común sobre el uso de contenedores son los gastos generales. loslos gastos generales de los contenedores dependen de su implementación, pero un documento de IBM2descubrió que la sobrecarga es bastante baja y, en general, más rápida que la virtualización. Con Kubeflow, hay algunosgastos generales de tener operadores instalados que no puede utilizar. Esta sobrecarga es insignificante en un clúster de producción, pero puede notarse en una computadora portátil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIPS :\n",
    "    \n",
    "    Los científicos de datos con experiencia en Python pueden pensar en los contenedores como un entorno virtual de alta resistencia. Además de lo que está acostumbrado en un entorno virtual, los contenedores también incluyen el sistema operativo, los paquetes y todo lo demás."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué Kubernetes?\n",
    "\n",
    "Kubernetes es un sistema de código abierto para automatizarimplementación, escalado y administración de aplicaciones en contenedores. Permite que nuestras canalizaciones sean escalables sin sacrificar la portabilidad, lo que nos permite evitar quedarnos bloqueados en un proveedor de nube específico.3Además de poder cambiar de una sola máquina a un clúster distribuido, las diferentes etapas de su canalización de aprendizaje automático pueden solicitar diferentes cantidades o tipos de recursos. Por ejemplo, su paso de preparación de datos puede beneficiarse más de la ejecución en varias máquinas, mientras que el entrenamiento de su modelo puede beneficiarse más de la computación en la parte superior de GPU o unidades de procesamiento tensorial (TPU). Esta flexibilidad es especialmente útil en entornos de nube, donde puede reducir sus costos utilizando recursos costosos solo cuando sea necesario.Por supuesto, puede crear sus propias canalizaciones de aprendizaje automático en contenedores en Kubernetes sin utilizar Kubeflow; sin embargo, el objetivo de Kubeflow es estandarizar este proceso y hacerlo sustancialmente más fácil y eficiente.4Kubeflow proporciona una interfaz común sobre las herramientas que probablemente usaría para sus implementaciones de aprendizaje automático. También facilita la configuración de sus implementaciones para usar aceleradores de hardware como TPU sin cambiar su código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLFlow es una API que le permite integrar los principios de MLOps en sus proyectos con cambios mínimos en el código existente. Con solo un par de líneas de código aquí y allá, puede rastrear todos los detalles relevantes para el proyecto que desea. Además, incluso puede guardar el modelo para usarlo en el futuro en la implementación, por ejemplo, y puede comparar todas las métricas entre modelos individuales para ayudarlo a seleccionar el mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
