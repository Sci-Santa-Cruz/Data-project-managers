{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"jumbotron\">\n",
    "  <h1><i class=\"fa fa-bar-chart\" aria-hidden=\"true\"></i> Online Learning</h1>\n",
    "  <p></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/machine-learning-for-streaming-data-with-creme-dacf5fb469df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos  clasificar los sistemas de Machine Learning bajo el siguiente criterio : el sistema puede aprender incrementalmente de un flujo de datos entrantes  o sistemas que  aprender de todo el conjunto de datos  mediantes  grandes bloques llamados batch\n",
    "\n",
    "#### Aprendizaje por lotes\n",
    "\n",
    "En el aprendizaje por lotes , el sistema es incapaz de aprender de forma incremental: debe ser entrenado utilizando todos los datos disponibles. Esto generalmente tomará mucho tiempo y recursos informáticos, por lo que generalmente se realiza sin conexión. Primero se entrena el sistema, y luego se pone en producción y se ejecuta sin más aprendizaje; solo aplica lo que ha aprendido. Esto esllamado aprendizaje fuera de línea .\n",
    "\n",
    "Si desea que un sistema de aprendizaje por lotes conozca nuevos datos (como un nuevo tipo de correo no deseado), debe capacitar una nueva versión del sistema desde cero en el conjunto de datos completo (no solo los nuevos datos, sino también los datos antiguos) ), luego detenga el sistema anterior y reemplácelo por el nuevo.\n",
    "\n",
    "Afortunadamente, todo el proceso de capacitación, evaluación y lanzamiento de un sistema de Machine Learning puede automatizarse con bastante facilidad (como se muestra en la Figura 1-3 ), por lo que incluso un sistema de aprendizaje por lotes puede adaptarse al cambio. Simplemente actualice los datos y entrene una nueva versión del sistema desde cero tantas veces como sea necesario.\n",
    "\n",
    "Esta solución es simple y a menudo funciona bien, pero la capacitación con el conjunto completo de datos puede tomar muchas horas, por lo que normalmente entrenaría un nuevo sistema sólo cada 24 horas o incluso sólo semanalmente. Si su sistema necesita adaptarse a datos que cambian rápidamente (por ejemplo, para predecir los precios de las acciones), entonces necesita una solución más reactiva. Además, la capacitación sobre el conjunto completo de datos requiere muchos recursos informáticos (CPU, espacio de memoria, espacio en disco, E/S de disco, E/S de red, etc.). \n",
    "\n",
    "\n",
    "Si tiene muchos datos y automatiza su sistema para entrenar desde cero todos los días, terminará costándole mucho dinero. Si la cantidad de datos es enorme, incluso puede ser imposible usar un algoritmo de aprendizaje por lotes. Finalmente, si su sistema necesita poder aprender de forma autónoma y tiene recursos limitados (por ejemplo, una aplicación de teléfono inteligente o un móvil en Marte), entonces transporta grandes cantidades de datos de entrenamiento y toma muchos recursos para entrenar durante horas cada  día no es una solución aceptable.\n",
    "\n",
    "Afortunadamente, una mejor opción en todos estos casos es utilizar algoritmos que sean capaces de aprender de manera incremental."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos de ML, salvo algunas excepciones, son cosas estáticas. Son esencialmente colecciones de parámetros. Después de entrenar un modelo, sus parámetros no cambian. Desde una perspectiva técnica, esa es una buena noticia.\n",
    "\n",
    "Como los parámetros del modelo no cambian, no necesita sincronizar entre las instancias del modelo. Es horizontalmente escalable, casi trivialmente. Y si somos honestos, la escalabilidad horizontal es el mejor tipo de escalabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si solo entrenamos un modelo una vez y nunca lo tocamos nuevamente, nos estamos perdiendo la información que más datos podrían proporcionarnos. Esto es especialmente importante en entornos donde los comportamientos cambian rápidamente. Las compras en línea son uno de esos entornos: un producto que es popular hoy puede ser casi olvidado mañana.\n",
    "Para reaccionar a los nuevos datos y crear una IA que aprenda con el tiempo, los profesionales de ML suelen hacer una de dos cosas:\n",
    "\n",
    "- Se entrenan manualmente en datos más nuevos y despliegan el modelo resultante una vez que están contentos con su rendimiento\n",
    "- Ellos programan capacitación sobre nuevos datos para tener lugar, por ejemplo, una vez por semana e implementan automáticamente el modelo resultante\n",
    "\n",
    "El 99.99 por ciento de las veces, cuando alguien afirma que \"nuestra IA mejora cuanto más la usas\", lo que realmente quieren decir es que han optado por el enfoque 2), programando la capacitación de nuevos modelos.\n",
    "\n",
    "Todo esto está muy bien, aparte de un problema evidente: incluso si entrena nuevos modelos cada semana, o incluso cada día, todavía se está quedando atrás. Su modelo nunca está completamente actualizado con los eventos actuales, porque está entrenado en datos obsoletos. Idealmente, lo que desea es un modelo que pueda aprender de nuevos ejemplos en algo cercano al tiempo real . No solo predice en tiempo real, sino que también aprende en tiempo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el aprendizaje en línea , usted entrenar el sistema de manera incremental al alimentarlo instancias de datos secuencialmente, ya sea individualmente o en pequeños grupos llamados mini lotes . Cada paso de aprendizaje es rápido y económico, por lo que el sistema puede aprender sobre los nuevos datos sobre la marcha, a medida que llegan (consulte la Figura )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mls2_0113 (1).png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje online es excelente para los sistemas que reciben datos como un flujo continuo (por ejemplo, precios de acciones) y necesitan adaptarse para cambiar de forma rápida o autónoma. También es una buena opción si tiene recursos informáticos limitados: una vez que un sistema de aprendizaje en línea se ha enterado de las nuevas instancias de datos, ya no las necesita, por lo que puede descartarlas (a menos que desee volver a una versión anterior estado y \"reproducir\" los datos). Esto puede ahorrar una gran cantidad de espacio.\n",
    "\n",
    "\n",
    "En los algoritmos de aprendizaje online también se pueden usar para entrenar sistemas en grandes conjuntos de datos que no pueden caber en la memoria principal de una máquina (esto se llama out-of-core learning ). El algoritmo carga parte de los datos, ejecuta un paso de entrenamiento sobre esos datos y repite el proceso hasta que se haya ejecutado en todos los datos (consulte la Figura )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    <H3>Advertencia</H3>\n",
    "    \n",
    "    \n",
    "\n",
    "el out-of-core learnig generalmente se realiza fuera de línea (es decir, no en el sistema en vivo), por lo que el aprendizaje en línea puede ser un nombre confuso. Piense en ello como un aprendizaje incremental .\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un __parámetro importante de los sistemas de aprendizaje online__ es qué tan rápido deben adaptarse a los datos cambiantes: esto se llama la _tasa de aprendizaje_ . Si establece una alta _tasa de aprendizaje_ , su sistema se adaptará rápidamente a los nuevos datos, pero también tenderá a olvidar rápidamente los datos antiguos (no desea que un filtro de spam marque solo los últimos tipos de spam que se mostraron) . Por el contrario, si establece una baja _tasa de aprendizaje_ , el sistema tendrá más inercia; es decir, aprenderá más lentamente, pero también será menos sensible al ruido en los datos nuevos o a secuencias de puntos de datos no representativos (valores atípicos).\n",
    "\n",
    "\n",
    "Implementar el aprendizaje en tiempo real no es fácil . Puede obtener muchos comentarios (ejemplos) de una cosa pero no de otra, lo que lleva a un problema de clases sesgadas.Puede que te sobreajustes o que te quedes por debajo. Alguien podría hacer DDoS en su sistema, arruinando el aprendizaje en el proceso. El aprendizaje en línea es propenso a interferencias catastróficas , más que la mayoría de las otras técnicas ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mls2_0114.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un gran desafío con el aprendizaje en línea es que si se __ingresan datos incorrectos al sistema__ , el rendimiento del sistema disminuirá gradualmente. Si es un sistema en vivo, sus clientes lo notarán. Por ejemplo, los datos incorrectos podrían provenir de un sensor que funciona mal en un robot, o de alguien que envía spam a un motor de búsqueda para tratar de obtener una clasificación alta en los resultados de búsqueda. Para reducir este riesgo, debe monitorear su sistema de cerca y desactivar rápidamente el aprendizaje (y posiblemente volver a un estado de funcionamiento anterior) si detecta una caída en el rendimiento. También es posible que desee monitorear los datos de entrada y reaccionar a datos anormales (por ejemplo, usando un algoritmo de detección de anomalías)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los puristas de ML pueden burlarse de la idea de algoritmos en línea para el aprendizaje en tiempo real. La __capacitación de un modelo puede salir mal de muchas maneras diferentes:__ el algoritmo en sí podría no ser adecuado, el modelo podría no generalizarse bien, la tasa de aprendizaje podría estar equivocada, la regularización podría ser demasiado baja o demasiado alta ... la lista continúa. ¿Por qué demonios intentaríamos aprender de inmediato cuando no hay garantías de lo que podría suceder?\n",
    "\n",
    "__La respuesta es simple__ : no importa cuán bueno sea un modelo o cuántos datos lo alimentes, un modelo sigue siendo una representación imperfecta de un entorno. Para tomar las mejores decisiones posibles en este momento, no podemos permitirnos tener un modelo que solo sepa sobre las cosas que sucedieron ayer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<H3>Key</H3> \n",
    "\n",
    "El aprendizaje automático por lotes es excelente, y funciona bien en muchos casos. Sin embargo, el aprendizaje automático en línea es una solución más adecuada para algunos casos de uso. Simplemente tiene sentido para aplicaciones donde constantemente llegan nuevos datos: filtrado de spam, sistemas de recomendación, sensores de IoT, transacciones financieras, etc.\n",
    "\n",
    "\n",
    "El uso de un modelo de aprendizaje automático en línea también puede reducir sus costos operativos, tanto en términos de potencia informática como de intervención humana. En primer lugar, no necesita un hardware potente para procesar un conjunto de datos de transmisión, porque solo un elemento de la transmisión vive en la memoria a la vez. De hecho, el aprendizaje automático en línea se puede implementar efectivamente en una Raspberry Pi. En segundo lugar, los científicos de datos pueden dedicar menos tiempo a la actualización del modelo porque las actualizaciones del modelo están integradas en el aprendizaje automático en línea y, por lo tanto, pueden dedicar más tiempo a tareas con más valor agregado.\n",
    "\n",
    "\n",
    " Otro beneficio es que su modelo siempre está actualizado . La consecuencia natural es que su modelo puede manejar _Concept drift_ , que ocurre cuando la distribución de datos evoluciona a medida que pasa el tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    <H3>Ejemplo</H3>\n",
    "\n",
    "Considere el siguiente ejemplo. Digamos que tenemos un sitio web de noticias. Personalizamos nuestras noticias mediante la recopilación de datos sobre lo que se hizo clic o no, y por quién. Con base en esta información, predecimos los tipos de noticias que pueden gustar a los diferentes visitantes y les servimos artículos relevantes.\n",
    "\n",
    "\n",
    "Un día, de la nada, se sabe que el gobierno está emitiendo un estado de emergencia, y llevará a cabo una conferencia de prensa en una hora. De repente, todos están interesados en los asuntos domésticos, incluso aquellos que generalmente solo leen sobre deportes o miran las risas. Cuando se le presenta una noticia sobre la conferencia, un gran porcentaje de la audiencia hace clic para obtener más información.\n",
    "\n",
    "Si hubiera seguido la ruta tradicional y haya entrenado por lotes su motor de recomendación una vez al día, todavía estaría atascado ofreciendo el mismo tipo de contenido, a pesar de que el mundo subyacente cambió drásticamente¹. Usted debe estar sirviendo a las noticias nacionales en este momento, pero no es porque su sistema es demasiado lento.\n",
    "\n",
    "Empeora: al día siguiente, después de la conferencia de prensa y después de un nuevo ciclo de entrenamiento, su motor comenzaría a recomendar activamente noticias nacionales que, después de 24 horas, ya no son necesariamente interesantes. Cometió dos errores, ambos porque no puede reaccionar lo suficientemente rápido.\n",
    "\n",
    "Ese es el poder del aprendizaje en línea: hecho correctamente, puede reaccionar en minutos o incluso segundos. Con él, no existen las \"noticias de ayer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumir el aprendizaje en línea no es fácil. No es un algoritmo de aprendizaje único: de hecho, muchos algoritmos pueden aprender en línea. Tampoco es fundamentalmente diferente en términos de cómo ocurre el aprendizaje: puede usar los mismos pasos de optimización que siempre hace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Computacionalmente mucho más rápido y más eficiente en el espacio.  En el modelo en línea, se le permite hacer exactamente un pase en sus datos, por lo que estos algoritmos suelen ser mucho más rápidos que sus equivalentes de aprendizaje por lotes, ya que la mayoría de los algoritmos de aprendizaje por lotes son de múltiples pasos. Además, dado que no puede reconsiderar sus ejemplos anteriores, generalmente no los almacena para acceder más adelante en el procedimiento de aprendizaje, lo que significa que tiende a usar una huella de memoria más pequeña.\n",
    "\n",
    "\n",
    "- Generalmente más fácil de implementar. Dado que el modelo en línea hace un pase sobre los datos, terminamos procesando un ejemplo a la vez, secuencialmente, a medida que ingresan de la transmisión. Esto generalmente simplifica el algoritmo, si lo hace desde cero.\n",
    "\n",
    "\n",
    "- Más difícil de mantener en producción. La implementación de algoritmos en línea en producción generalmente requiere que tenga algo que constantemente transfiera puntos de datos a su algoritmo. Si sus datos cambian y sus selectores de funciones ya no producen resultados útiles, o si hay una latencia de red importante entre los servidores de sus selectores de funciones, o uno de esos servidores se cae, o realmente, cualquier otra cantidad de cosas, sus estudiantes se concentran y tu salida es basura. Asegurarse de que todo esto funcione correctamente puede ser una prueba.\n",
    "\n",
    "\n",
    "- Más difícil de evaluar en línea. En el aprendizaje en línea, no podemos ofrecer un conjunto de \"prueba\" para evaluación porque no estamos haciendo suposiciones de distribución: si seleccionamos un conjunto para evaluar, estaríamos asumiendo que el conjunto de prueba es representativo de los datos que estamos operando, y esa es una suposición distributiva. Dado que, en el caso más general, no hay forma de obtener un conjunto representativo que caracterice sus datos, su única opción (nuevamente, en el caso más general) es simplemente observar qué tan bien ha ido el algoritmo recientemente.\n",
    "\n",
    "\n",
    "- Por lo general, es más difícil \"acertar\". Como vimos en el último punto, la evaluación en línea del alumno es difícil. Por razones similares, puede ser muy difícil lograr que el algoritmo se comporte \"correctamente\" de forma automática. Puede ser difícil diagnosticar si su algoritmo o su infraestructura se están portando\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### out-of-core learning \n",
    "\n",
    "El aprendizaje fuera del núcleo se refiere a un conjunto de algoritmos que trabajan con datos que no pueden caber en la memoria de una sola computadora, pero que pueden caber fácilmente en algún almacenamiento de datos, como un disco duro local o un repositorio web. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tal situación, siempre puede intentar reducir su conjunto de datos reduciendo el número de instancias o limitando el número de características, reduciendo así las dimensiones de la matriz del conjunto de datos y su área ocupada en la memoria. Reducir el tamaño del conjunto de datos, al elegir solo una parte de las observaciones, es una solución llamada submuestreo (o simplemente muestreo). El submuestreo no es incorrecto per se, pero tiene serios inconvenientes y es necesario tenerlos en cuenta antes de decidir el curso del análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En consecuencia, el submuestreo, aunque aceptable como solución, puede imponer un límite en los resultados de sus actividades de aprendizaje automático debido a predicciones menos precisas y una mayor variación de las estimaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submuestreo como una opción viable\n",
    "\n",
    "Cuando submuestras, en realidad estás descartando parte de tu riqueza de información y no puedes estar tan seguro de quesolo descartan observaciones redundantes, no tan útiles. En realidad, algunas gemas ocultas se pueden encontrar solo considerando todos los datos. Aunque computacionalmente atractivo, porque el submuestreo solo requiere un generador aleatorio que le diga si debe elegir una instancia o no, al elegir un conjunto de datos submuestreado, realmente corre el riesgo de limitar las capacidades de su algoritmo para aprender las reglas y asociaciones en sus datos en un completo camino. \n",
    "\n",
    "En el equilibrio de sesgo-varianza, el submuestreo causa una inflación de varianza de las predicciones porque las estimaciones serán más inciertas debido al ruido aleatorio u observaciones externas en sus datos.En un mundo de grandes datos, el algoritmo con más datos de calidad gana porque puede aprender más formas de relacionar predicciones con predictores que otros modelos con menos (o más ruidosos) datos. \n",
    "\n",
    "En consecuencia, el submuestreo, aunque aceptable como solución, puede imponer un límite en los resultados de sus actividades de aprendizaje automático debido a predicciones menos precisas y una mayor variación de las estimaciones.Las limitaciones de submuestreo se pueden superar de alguna manera aprendiendo múltiples modelos en múltiples submuestras de datos y luego finalmente uniendo todas las soluciones o apilando los resultados de todos los modelos juntos, creando así una matriz de datos reducida para capacitación adicional. Este procedimiento se conoce como embolsado. (Realmente comprime las características de esta manera, reduciendo así el espacio de sus datos en la memoria). \n",
    "\n",
    "Exploraremos el ensamblaje y el apilamiento en un capítulo posterior y descubriremos cómo pueden reducir realmente la varianza de las estimaciones infladas por el submuestreo.Como alternativa, en lugar de cortar las instancias, podríamos cortar las características, pero nuevamente, tendremos el problema de que necesitamos construir un modelo a partir de los datos para probar qué características podemos seleccionar, por lo que todavía tenemos que construir Un modelo con datos que no pueden caber en la memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizando una instancia a la vez\n",
    "\n",
    "Habiendo comprendido eso, el submuestreo, aunque siempre es viable, no es una solución óptima, tenemos que evaluar un enfoque diferente y fuera del núcleo en realidad no requiere que renuncies a observaciones o características. Solo lleva un poco más de tiempo entrenar un modelo, lo que requiere más iteraciones y transferencia de datos desde su almacenamiento a la memoria de su computadora. Inmediatamente proporcionamos una primera intuición de cómo funciona un proceso de aprendizaje fuera del núcleo.\n",
    "\n",
    "Comencemos por el aprendizaje, que es un proceso en el que tratamos de mapear la función desconocida que expresa una respuesta (un número o resultado que es un problema de regresión o clasificación) con respecto a los datos disponibles. El aprendizaje es posible ajustando los coeficientes internos del algoritmo de aprendizaje tratando de lograr el mejor ajuste en los datos disponibles que minimiza una función de costo, una medida que nos dice qué tan buena es nuestra aproximación. \n",
    "\n",
    "\n",
    "En resumen, estamos hablando de un proceso de optimización. Los diferentes algoritmos de optimización, como el descenso de gradiente, son procesos capaces de trabajar en cualquier volumen de datos. Trabajan para derivar un gradiente para la optimización (una dirección en el proceso de optimización) y hacen que el algoritmo de aprendizaje adapte sus parámetros para seguir el gradiente. En el caso específico del descenso de gradiente, después de un cierto número de iteraciones, si el problema se puede resolver y no hay otros problemas, como una tasa de aprendizaje demasiado alta, el gradiente debería ser tan pequeño que podamos detener el proceso de optimización. \n",
    "\n",
    "Al final del proceso, podemos estar seguros de haber encontrado una solución óptima (porque es un óptimo global, aunque a veces puede ser un mínimo local, si la función aproximada no es convexa). Como la direccionalidad, dictada por el gradiente, se puede tomar en función de cualquier volumen de ejemplos, también se puede tomar en una sola instancia. Tomar el gradiente en una sola instancia requiere un pequeña tasa de aprendizaje, pero al final, el proceso puede llegar a la misma optimización que un descenso de gradiente en los datos completos. \n",
    "\n",
    "Al final, todo lo que nuestro algoritmo necesita es una dirección para orientar correctamente el proceso de aprendizaje al ajustar los datos disponibles. Por lo tanto, aprender tal dirección de un solo caso tomado aleatoriamente de los datos es perfectamente factible:\n",
    "\n",
    "- Podemos obtener los mismos resultados que si estuviéramos trabajando en todos nuestros datos al mismo tiempo, aunque la ruta de optimización puede volverse un poco difícil;  Si la mayoría de sus observaciones apuntan a una dirección óptima, el algoritmo tomará esa. El único problema será ajustar correctamente los parámetros correctos del proceso de aprendizaje y pasar los datos varias veces para asegurarse de que se complete la optimización, ya que este procedimiento de aprendizaje es mucho más lento que trabajar con todos los datos disponibles.\n",
    "\n",
    "\n",
    "- No tenemos ningún problema en particular al lograr mantener una sola instancia en nuestra memoria central, dejando fuera la mayor parte de los datos. Pueden surgir otros problemas al mover los datos mediante ejemplos únicos desde su repositorio a nuestra memoria central. La escalabilidad está asegurada porque el tiempo que lleva procesar los datos es lineal; El costo de tiempo de usar una instancia más es siempre el mismo, sin importar el número total de instancias que tengamos que procesar.\n",
    "\n",
    "El enfoque de ajustar un algoritmo de aprendizaje en una sola instancia o un subconjunto de ajuste de datos a la memoria a la vez se llama aprendizaje en línea y el descenso de gradiente basado en tales observaciones individuales se llama descenso de gradiente estocástico.\n",
    "\n",
    "Como se sugirió anteriormente, el aprendizaje en línea es una técnica fuera del núcleo y adoptada por muchos algoritmos de aprendizaje en Scikit-learn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Python: Real World Machine Learning \n",
    "Prateek Joshi; John Hearty; Luca Massaron; Bastiaan Sjardin; Alberto Boschetti\n",
    "Packt Publishing , 2016\n",
    "\"\"\"\n",
    "h=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la clasificación, una cosa algo importante a tener en cuenta es que, aunque una rutina de extracción de características sin estado puede hacer frente a atributos nuevos / invisibles, el alumno incremental en sí mismo puede ser incapaz de hacer frente a clases de objetivos nuevos / invisibles. En este caso, debe pasar todas las clases posibles a la primera llamada partial_fit utilizando el parámetro classes = .\n",
    "\n",
    "Otro aspecto a tener en cuenta al elegir un algoritmo adecuado es que todos ellos no le dan la misma importancia a cada ejemplo con el tiempo. Es decir, el Perceptron sigue siendo sensible a ejemplos mal etiquetados, incluso después de muchos ejemplos, mientras que las familias SGD * y PassiveAggressive * son más robustas para este tipo de artefactos. Por el contrario, los últimos también tienden a dar menos importancia a los ejemplos notablemente diferentes, pero debidamente etiquetados, cuando llegan tarde en la corriente a medida que su tasa de aprendizaje disminuye con el tiempo.\n",
    "\n",
    "Dependiendo del algoritmo, el tamaño del mini lote puede influir en los resultados o no. SGD *, PassiveAggressive * y NaiveBayes discretos están realmente en línea y no se ven afectados por el tamaño del lote. Por el contrario, la tasa de convergencia de MiniBatchKMeans se ve afectada por el tamaño del lote. Además, su huella de memoria puede variar dramáticamente con el tamaño del lote.\n",
    "\n",
    "\n",
    "En los modelos de aprendizaje estadístico, la muestra de entrenamiento  se supone que han sido extraídos de la verdadera distribución de los datos y etiquetas y el objetivo es minimizar el \"riesgo\" esperado.\n",
    "\n",
    "\n",
    "Un modelo puramente en línea en esta categoría aprendería basándose solo en la nueva entrada, el mejor predictor actual y alguna información adicional almacenada (que generalmente se espera que tenga requisitos de almacenamiento independientes del tamaño de los datos de entrenamiento). Para muchas formulaciones, por ejemplo , métodos de kernel , el verdadero aprendizaje en línea no es posible, aunque se puede usar una forma de aprendizaje híbrido en línea con algoritmos recursivos donde $f_{t-1}$ se le permite depender de $f_t$ y de todos las muetras anteriores.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizaje incremental \n",
    "\n",
    "\n",
    "En informática , el aprendizaje incremental es un método de aprendizaje automático en el que los datos de entrada se utilizan continuamente para ampliar el conocimiento del modelo existente, es decir, para entrenarlo aún más. Representa una técnica dinámica de aprendizaje supervisado y aprendizaje no supervisado que se puede aplicar cuando los datos de entrenamiento están disponibles gradualmente con el tiempo o su tamaño está fuera de los límites de memoria del sistema. Los algoritmos que pueden facilitar el aprendizaje incremental se conocen como algoritmos incrementales de aprendizaje automático.\n",
    "\n",
    "Muchos algoritmos tradicionales de aprendizaje automático admiten inherentemente el aprendizaje incremental. Se pueden adaptar otros algoritmos para facilitar el aprendizaje incremental. Los ejemplos de algoritmos incrementales incluyen árboles de decisión (IDE4, [1] ID5R [2] ), reglas de decisión , [3] redes neuronales artificiales ( redes RBF , [4] Learn ++, [5] Fuzzy ARTMAP, [6] TopoART, [7 ] e IGNG [8] ) o la SVM incremental . [9]\n",
    "\n",
    "El objetivo del aprendizaje incremental es que el modelo de aprendizaje se adapte a los nuevos datos sin olvidar su conocimiento existente, no vuelve a capacitar al modelo. Algunos aprendices incrementales han incorporado algún parámetro o supuesto que controla la relevancia de los datos antiguos, mientras que otros, llamados algoritmos de aprendizaje automático incrementales estables, aprenden representaciones de los datos de entrenamiento que ni siquiera se olvidan parcialmente con el tiempo. Fuzzy ART [10] y TopoART [7] son dos ejemplos de este segundo enfoque.\n",
    "\n",
    "Los algoritmos incrementales se aplican con frecuencia a flujos de datos o big data , abordando problemas de disponibilidad de datos y escasez de recursos, respectivamente. La predicción de la tendencia de las acciones y el perfil del usuario son algunos ejemplos de flujos de datos en los que los nuevos datos están continuamente disponibles. La aplicación de aprendizaje incremental a big data tiene como objetivo producir tiempos de clasificación o pronóstico más rápidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gradual unlearning and interference catastrophic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La interferencia catastrófica , también conocida como olvido catastrófico, es la tendencia de una red neuronal artificial a olvidar completa y abruptamente la información previamente aprendida al aprender nueva información. [1] [2] Las redes neuronales son una parte importante del enfoque de red y el enfoque conexionista de la ciencia cognitiva . Estas redes utilizan simulaciones por computadora para tratar de modelar comportamientos humanos, como la memoria y el aprendizaje. \n",
    "\n",
    "La interferencia catastrófica es un tema importante a considerar al crear modelos conexionistas de memoria. Originalmente fue señalado a la atención de la comunidad científica por investigaciones de McCloskey y Cohen (1989), [1] y Ratcliff (1990). [2]Es una manifestación radical del dilema 'sensibilidad-estabilidad' [3] o el dilema 'estabilidad-plasticidad'. [4] Específicamente, estos problemas se refieren al problema de poder crear una red neuronal artificial que sea sensible a, pero no sea interrumpida por, nueva información. Las tablas de búsqueda y las redes conexionistas se encuentran en los lados opuestos del espectro de plasticidad de estabilidad. [5] El primero permanece completamente estable en presencia de nueva información, pero carece de la capacidad de generalizar , es decir, inferir principios generales, a partir de nuevas entradas. \n",
    "\n",
    "Por otro lado, las redes conexionistas, como la red estándar de retropropagaciónson muy sensibles a la nueva información y pueden generalizar sobre nuevas entradas. Los modelos de retropropagación pueden considerarse buenos modelos de memoria humana en la medida en que reflejan la capacidad humana de generalizar, pero estas redes a menudo exhiben menos estabilidad que la memoria humana. En particular, estas redes de retropropagación son susceptibles a interferencias catastróficas. Esto se considera un problema cuando se intenta modelar la memoria humana porque, a diferencia de estas redes, los humanos generalmente no muestran olvidos catastróficos. Por lo tanto, la cuestión de la interferencia catastrófica debe ser erradicada de estos modelos de retropropagación para mejorar la plausibilidad como modelos de memoria humana.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Catastrophic_interference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catastrophic interference\n",
    "\n",
    "\n",
    "Los estudios de aprendizaje asociativo en sistemas de aprendizaje tanto humanos como conexionistas han prestado mucha atención al fenómeno de la interferencia catastrófica.(Barnes y Underwood, 1959; McCloskey y Cohen 1989; Ratcliff, 1990).\n",
    "\n",
    "El fenómeno se ilustra con mayor facilidad utilizando el paradigma utilizado clásicamente para demostrarlo. Barnes y Underwood (1959) entrenaron sujetos para asociar elementos de una lista (Lista A) con elementos de otra lista (Lista B). Cuando se aprendieron estas asociaciones A->B, se aprendió un segundo conjunto de asociaciones, en este caso entre los elementos de la Lista A y un nuevo conjunto de elementos, los elementos de la Lista C. La cuestión de interés es la medida en que las asociaciones de CA aprendidas más recientemente interfieren o sobrescriben las asociaciones de AB aprendidas por primera vez. Barnes y Underwood encontraron un olvido gradual e incompleto de las asociaciones AB durante el aprendizaje de las asociaciones AC, e incluso cuando las asociaciones AC se aprendieron por completo, se retuvo mucha memoria para las asociaciones AB originales. \n",
    "\n",
    "\n",
    "En otras palabras, el aprendizaje de nueva información sólo interfiere parcial y gradualmente con el conocimiento almacenado existente. Este fenómeno ha atraído un interés particular en los últimos años, porque parece que los modelos conexionistas de aprendizaje y memoria sufrieron una \"interferencia catastrófica\" en ese aprendizaje, el nuevo conjunto de asociaciones (las asociaciones de CA) causó un rápido y total olvido del primer AB aprendido. asociaciones (por ejemplo, McCloskey y Cohen, 1989). Esta es una interferencia catastrófica. porque parece que los modelos conexionistas de aprendizaje y memoria sufrieron de \"interferencia catastrófica\" en ese aprendizaje, el nuevo conjunto de asociaciones (las asociaciones AC) causó un olvido rápido y total de las asociaciones AB aprendidas por primera vez (por ejemplo, McCloskey y Cohen, 1989) . \n",
    "\n",
    "\n",
    "\n",
    "Ratcliff (1990) analizó más a fondo las condiciones bajo las cuales ocurre una interferencia catastrófica. El paradigma AB-AC, como se conoce, captura un aspecto importante de la tarea que enfrentan los niños a medida que aprenden a leer. En este caso, las representaciones ortográficas y fonológicas son los patrones para asociarse entre sí. Así como más de un elemento se asocia a cada elemento de la Lista A en el paradigma de Barnes y Underwood, más de un patrón fonológico puede asociarse a un segmento ortográfico dado. Por lo tanto, será claramente indeseable si, después de haber aprendido inicialmente que la secuencia ortográfica - ave es pronunciado / EIV / (como en delirio, dio, guardar , etc.), el aprendizaje posterior que - ave es a veces pronunciado / Av / como en tieneelimina completamente el conocimiento previo de la asociación original. En otras palabras, es importante asegurar que se evite la interferencia catastrófica al aprender el mapeo de la ortografía al sonido. En la literatura de modelos conexionistas, se han propuesto varias soluciones al problema de la interferencia catastrófica (por ejemplo, French, 1992; Lewandowsky, 1991). Sin embargo, lo más interesante para la presente propuesta es un tipo de aprendizaje conocido como aprendizaje intercalado (McClelland, McNaughton y O'Reilly, 1995).Aprendizaje Intercalado y Aprendizaje de Pendiente de GradienteUna visión reciente de los sistemas de aprendizaje conexionista se refiere a la necesidad de que sean posibles dos tipos de aprendizaje completamente diferentes (McClelland et al., 1995). Por un lado, es necesario poder almacenar representaciones distinguibles de eventos (quizás similares) después de una sola exposición. Por otro lado, ya está bien establecido que los procedimientos de aprendizaje incremental lento, en los que los pesos en una red cambian solo una pequeña cantidad después de la presentación de cada elemento en el conjunto que se va a aprender, son buenos para extraer regularidades subyacentes en el mapeo para ser aprendido. En tales sistemas, se asignan representaciones similares a elementos similares. Por lo tanto, estos procedimientos de aprendizaje incremental lento (p. Ej., Algoritmos de aprendizaje de descenso de gradiente, como la propagación hacia atrás en redes conexionistas) se adaptan bien al desarrollo de sistemas que son buenos para la generalización. Esto se debe a que la estructura del sistema subyacente solo cambia una pequeña cantidad en respuesta a cada ejemplar presentado y, por lo tanto, una sola instancia atípica no puede tener una influencia demasiado grande en la estructura subyacente de la red. Esto lleva a un sistema que es (a) sensible a las regularidades subyacentes en el mapeo a aprender, y (b) bueno en generalización, porque ha extraído lo que es común a todos los ejemplos con los que se ha presentado.(Plaut et al., 1996; Seidenberg y McClelland, 1989) o el sistema de tiempo verbal en inglés (Plunkett y Marchman, 1991, 1993; Rumelhart y McClelland, 1986).Otra característica importante de estos sistemas es que evitan la interferencia catastrófica mencionada anteriormente porque usan lo que McClelland et al. (1995) denominado aprendizaje intercalado. Esto significa que no se presentan todos los ejemplos a la vez, en bloques, sino que están \"intercalados\" (de modo que, por ejemplo, los ejemplos irregulares se intercalarían entre los ejemplos regulares). Esto tiene la consecuencia adicional de que las frecuencias relativas de diferentes ejemplos se pueden representar con precisión en las fuerzas de conexión del sistema completamente aprendido. Queda por ver hasta qué punto estos hallazgos pueden generalizarse al caso de aprender a leer. Sin embargo, sobre la base de los resultados computacionales ya establecidos, parece probable que el aprendizaje intercalado proporcione el método más eficiente para terminar con un sistema en el que se puedan representar correspondencias regulares e irregulares de ortografía a sonido. Así, por ejemplo, la práctica en masa de artículos regulares o consistentes, seguida de la práctica en masa de artículos irregulares, sería probable (si el análisis anterior se aplica al aprendizaje de lectura real) conducir a un olvido indeseable de las regularidades aprendidas originalmente. Dado que el sistema final debe codificar tanto las correspondencias regulares de ortografía al sonido como las excepciones a esas regularidades, parece probable que el aprendizaje intercalado de elementos regulares y excepcionales sea más eficiente.4 4Se ha realizado poca investigación empírica sobre el tema de cómo introducir elementos regulares e irregulares en la lectura de los niños, aunque investigadores como Kryzanowski y Carnine (1980), así como otros, encontraron la ventaja general esperada para la práctica distribuida versus masiva, en uno En el estudio, casi el doble de respuestas correctas de nombres posteriores al entrenamiento se hicieron a las letras cuando se presentaron en patrones distribuidos en lugar de bloqueados (véase también Rea y Modigliani, 1985). Sin embargo, este estudio solo examinó las respuestas a letras individuales, y es posible que el aprendizaje intercalado pueda ser particularmente importante en condiciones en las que las respuestas múltiples deben estar asociadas con una sola entrada (como con segmentos ortográficos pronunciados de manera ambigua o inconsistente).Por lo tanto, existe al menos evidencia sugestiva de que el aprendizaje intercalado puede proporcionar la mejor manera de evitar interferencias catastróficas en la inclinación de los sistemas de mapeo de entrada-salida, como el mapeo de ortografía a sonido en inglés sistema, así como extraer las regularidades estructurales subyacentes relevantes que permitirán la generalización. Queda por ver si las predicciones de esta cuenta pueden confirmarse experimentalmente.A continuación se revisa la evidencia adicional sobre las condiciones bajo las cuales es más fácil que los artículos regulares y excepcionales se representen en el mismo sistema.LA IMPORTANCIA DE LA FRECUENCIA RELATIVAAl estudiar la adquisición del aprendizaje del tiempo verbal, Plunkett y Marchman (1991) delinearon algunas restricciones importantes sobre las condiciones bajo las cuales las excepciones y excepciones / subregularidades pueden representarse dentro del mismo sistema. Una revisión completa de esta investigación está más allá del alcance de este capítulo, pero para los propósitos actuales se puede enfatizar una conclusión significativa. Esto es que, en una red asociativa simple, las excepciones solo se pueden representar de forma estable en un sistema donde hay regularidades subyacentes y conflictivas si los elementos de excepción tienen una frecuencia suficientemente alta. Si la frecuencia (simbólica) de elementos excepcionales es demasiado baja, entonces es difícil o imposible asociar la salida correcta con ellos, ya que la tendencia a regularizar esos elementos debido a la alta frecuencia de los elementos regulares se vuelve demasiado fuerte. Por lo tanto, no parece ser casualidad que en los sistemas de idiomas como el sistema de ortografía y sonido en inglés o la formación del tiempo verbal, los elementos irregulares tienden a tener una frecuencia de token alta. Esto parece ser una consecuencia computacional de la necesidad de representar excepciones y regularidades en el mismo sistema.Nuevamente, esto tiene implicaciones importantes para el aprendizaje. Sugiere que podría ser un error evitar, en la medida de lo posible, elementos excepcionales en las primeras etapas del aprendizaje de la lectura, porque los elementos irregulares se inundarán y serán difíciles o imposibles de representar si tienen una frecuencia de fichas demasiado baja. Nuevamente, hay una escasez de evidencia empírica sobre esta cuestión. Aunque todavía no hay evidencia en su contra, la conclusión debe ser tentativa, y la posibilidad adicional sigue siendo que un énfasis temprano en los ítems regulares puede llevar a un enfoque útil en los niveles de representación sobre los cuales se pueden definir las regularidades. La importancia de las representaciones se discute en la siguiente sección.LA IMPORTANCIA DE LA REPRESENTACIÓNDespués del influyente modelo de lectura conexionista de Seidenberg y McClelland (1989), mucha investigación ha demostrado que la naturaleza de las representaciones que proporciona un modelo de lectura conexionista tiene unaGran impacto en su rendimiento. El modelo de Seidenberg y McClelland fue criticado por su bajo rendimiento de lectura sin palabras (Besner, Twilley, McCann y Seergobin, 1990), pero se puede obtener un mejor rendimiento sin palabras si se utilizan representaciones más detalladas de entrada y salida. Esto permite que la red capture más fácilmente generalizaciones a nivel de grafemas y fonemas (por ejemplo, Brown, 1997; Bullinaria, 1995; Norris, 1994; Plaut et al., 1996). Por lo tanto, un modelo provisto de representaciones explícitas en muchos niveles diferentes funcionará bien (Norris, 1994; ver también Phillips, Hay y Smith, 1993). Además, se ha argumentado que algunos déficits paradójicos asociados con la dislexia del desarrollo pueden explicarse en términos de la capacidad computacional de una red (Brown y Loosemore, 1995; Seidenberg y McClelland, 1989) o, alternativamente, en términos de la especificidad de las representaciones dadas al modelo (Brown, 1997; Metsala & Brown, en prensa). Finalmente, está bien establecido que una red aprenderá más fácilmente si cuenta con representaciones fonológicas preestructuradas (Harm, Altmann y Seidenberg, 1994; Hulme, Snowling y Quinlan, 1991). Otras extensiones del enfoque han estado más preocupadas por introducir rutas alternativas en el modelo.Esta evidencia de la importancia de la representación, por supuesto, no sorprenderá a los involucrados en la instrucción de lectura (véase, por ejemplo, Stahl y Murray, cap. 3 , este volumen; Torgesen y Burgess, cap. 7 , este volumen). Sin embargo, los resultados computacionales descritos aquí permiten comprender cómo la importancia de desarrollar las representaciones fonológicas y ortográficas correctas puede entenderse como el comportamiento de un sistema que se desarrolla hacia un punto final que se caracteriza por un comportamiento estadísticamente óptimo en un dominio cognitivo dado.DISCUSIÓNEl objetivo de este capítulo ha sido mostrar que las nuevas perspectivas sobre la naturaleza de la lectura adulta capacitada pueden tener implicaciones importantes para nuestra comprensión de la mejor manera de enseñar habilidades de lectura. Aunque aún queda mucha investigación por hacer, se ha revisado la evidencia empírica consistente con la idea de que la lectura adulta experta involucra un comportamiento estadísticamente óptimo o adaptativo racional. Por lo tanto, el proceso de aprender a decodificar el sistema de ortografía a sonido puede verse como una sola instancia del proceso cognitivo general de internalizar la estructura estadística del entorno. Esta visión lleva naturalmente a un énfasis en el papel de la estructuración de tareas en la instrucción.Una consecuencia de esta perspectiva es que los resultados generales obtenidos del estudio del aprendizaje estadístico se vuelven relevantes para la instrucción de lectura. La sección final llamó la atención sobre algunos resultados del estudio del aprendizaje en sistemas conexionistas y sugirió que estos resultados podrían tener implicacionespara el proceso de instrucción de alfabetización. Relativamente poco trabajo empírico ha abordado estos temas. Becker, Carnine, Engelmann y sus colegas realizaron algunos trabajos relevantes a principios de la década de 1980 como su teoría de la instrucción. El modelo de instrucción directa (p. Ej., Becker, Engelmann, Carnine y Rhine, 1981) se basó en el supuesto de que el aprendizaje en el aula se puede mejorar mediante una ingeniería cuidadosa de la interacción de los estudiantes con el entorno que se va a aprender. Este programa de investigación enfatizó la importancia del análisis de similitud y diferencias entre los ejemplos utilizados en la enseñanza. El objetivo era identificar, en los aportes a aprender, la base estructural para la generalización. En términos generales, esto encaja bien con las ideas del aprendizaje computacional descritas anteriormente. Como señalaron Carnine y Becker (1982), Se ha llevado a cabo un enorme trabajo sobre la generalización del estímulo bajo la bandera de la teoría del aprendizaje. Se centraron en las implicaciones para la generalización en el aprendizaje de la lectura. ¿Cómo se estructura un conjunto de ejemplos para garantizar la máxima generalización, y cómo se debe informar el diseño sobre la base de la estructura subyacente de igualdad y diferencia en los ejemplos que se utilizarán? Gran parte del enfoque de instrucción directa fue motivado para llamar la atención sobre contrastes significativos, mediante el uso de conjuntos de ejemplos de entrenamiento que son mínimamente diferentes entre sí (ver, por ejemplo, Carnine y Becker, 1982). Sobre la base de los resultados computacionales descritos anteriormente, Se sugiere que hay muchas razones para creer que el aprendizaje del sistema de mapeo de ortografía al sonido en inglés se puede facilitar enormemente si se introducen elementos regulares e inconsistentes en un orden apropiado, con la frecuencia apropiada, y si la práctica se programa cuidadosamente para facilitar mantenimiento y generalización (Rea y Modigliani, 1985; Schmidt y Bjork, 1992). Hay poca evidencia de que la práctica educativa actual se acerque a la optimización en cualquiera de estos aspectos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Word Recognition in Beginning Literacy\n",
    "by Jamie L. Metsala, Linnea C. Ehri\n",
    "Publisher: Routledge\n",
    "Release Date: June 2013\n",
    "ISBN: 9781135680060\n",
    "\"\"\"\n",
    "h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
